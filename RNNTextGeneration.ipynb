{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc51a30c-61cb-4403-9927-4f440de87d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f330a1d-b7ce-4d50-8074-85e0e22ff592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
      "1115394/1115394 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "filepath = tf.keras.utils.get_file('poems1.txt',\"https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\")\n",
    "text = open(filepath,'rb').read().decode(encoding = 'utf-8').lower()\n",
    "text = text[300000:800000]\n",
    "\n",
    "characters = sorted(set(text))\n",
    "char_to_index = dict((c,i) for i,c in enumerate(characters))\n",
    "index_to_char = dict((i,c) for i,c in enumerate(characters))\n",
    "\n",
    "SEQ_LENGTH = 40\n",
    "STEP_SIZE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49c3dc9e-c1d1-4345-a7de-56e4be8113a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "next_characters = []\n",
    "for i in range(0, len(text) - SEQ_LENGTH,STEP_SIZE):\n",
    "    sentences.append(text[i:SEQ_LENGTH])\n",
    "    next_characters.append(text[i+SEQ_LENGTH])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "137ae067-75b2-423b-86f4-cb16b52c5c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((len(sentences),SEQ_LENGTH,len(characters)), dtype = bool)\n",
    "y = np.zeros((len(sentences),len(characters)), dtype = bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3395eb7d-cbdb-4ac1-8102-aee9e18a7af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,sentence in enumerate(sentences):\n",
    "    for t, character in enumerate(sentence):\n",
    "        x[i,t,char_to_index[character]] = 1\n",
    "    y[i,char_to_index[next_characters[i]]] = 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40c09772-24e0-4bd6-8ec5-32d3e73268a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "651/651 [==============================] - 66s 97ms/step - loss: 3.0783\n",
      "Epoch 2/4\n",
      "651/651 [==============================] - 55s 84ms/step - loss: 3.0677\n",
      "Epoch 3/4\n",
      "651/651 [==============================] - 53s 82ms/step - loss: 3.0673\n",
      "Epoch 4/4\n",
      "651/651 [==============================] - 50s 77ms/step - loss: 3.0666\n",
      "INFO:tensorflow:Assets written to: textgenerator.model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: textgenerator.model/assets\n"
     ]
    }
   ],
   "source": [
    "\"\"\"model = Sequential()\n",
    "model.add(LSTM(128,input_shape = (SEQ_LENGTH,len(characters))))\n",
    "model.add(Dense(len(characters)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = RMSprop(lr = 0.01))\n",
    "model.fit(x,y,batch_size = 256,epochs = 4)\n",
    "model.save('textgenerator.model')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0d228e22-b0c6-4c7d-9562-58af4894e0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RestoredOptimizer` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RestoredOptimizer`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('textgenerator.model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3544fdc8-5543-4d50-8a8a-4d6d76ef8d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds,temperature = 1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds)/temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1,preds,1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5f4e2768-c8db-459e-bf5c-cbbb9111c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(length,temperature):\n",
    "    start_index = random.randint(0,len(text) - SEQ_LENGTH - 1)\n",
    "    generated = ''\n",
    "    sentence = text[start_index:start_index + SEQ_LENGTH]\n",
    "    generated += sentence\n",
    "    for i in range(length):\n",
    "        x = np.zeros((1,SEQ_LENGTH,len(characters)))\n",
    "        for t,character in enumerate(sentence):\n",
    "            x[0,t,char_to_index[character]] = 1\n",
    "\n",
    "        predictions = model.predict(x,verbose = 0)[0]\n",
    "        next_index = sample(predictions,temperature)\n",
    "        next_character = index_to_char[next_index]\n",
    "        generated += next_character\n",
    "        sentence = sentence[1:] + next_character\n",
    "    return generated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfd5f2c0-d30d-4b86-84fc-644716ac911e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y are never curst but when they\n",
      "are hung h    e                             t          e e                       e e                    n          t            t       t        e                            e   t                    e                 t         e      an                  r            e                                    e e \n"
     ]
    }
   ],
   "source": [
    "print(generate_text(300,0.2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d123559e-dc55-4728-9ac4-1b0aecc4b132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now.\n",
      "\n",
      "capulet:\n",
      "a jealous hood, a jealoused   d  sn y ors  i eit ea     et : n  tsae la    t   w t o e  stsot\n",
      "ih e  df  a dn oer ee t sn ti   ohohde ee  tte  o so  ,et     t .da      tal  e  r  d e    hrem ha wo a  dte h  ono  i  len   e  \n",
      "a  er  etar ecs  uo  h ht  n\n",
      "e red eeewt  a ats\n",
      "hod eee  me\n",
      "aouhsns eo nd  t  p  e  ts  r \n",
      " u oaeo yh\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(300,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e037a82f-a7e7-4300-9fe2-3fc843e15445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " in them;\n",
      "and shall the figure of god's  rteaeur toe, !aeseelaenty eief\n",
      " ulhuhr atfo m ea p\n",
      " e  py uo ertnot u dte th oi dcm eso na  i ttetbeclie  dta t si llr\n",
      "setatfayo'e i ne r t orrtlpodryhta us \n",
      "   sel\n",
      " hp mea n hy detlull ca\n",
      "notatiow eei     y  nei iet viw ohtmshunaosedv ytt\n",
      "ie   ret f eonkrntnrtirc asuih,syat  t p od e,ig lo  erti h\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(300,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93392ce7-528e-4994-b0a2-d4fd0f122454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will strike\n",
      "where 'tis predominant; and  io oolstonrri enenanwtia\n",
      " e toed or o y  td  acn s sn  sf? ee:  poo\n",
      "h   o ntnaeitt  a  b etet ti dho  ke  eirnoho.wrteutw ti onp gof\n",
      "be.auy ant e!\n",
      "neree ye\n",
      "nyt ui aldt amrooe  nn \n",
      "oattn?e thdaatomsld\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(200,0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff74896-3091-4bb2-a7a2-6cb5a5a2ff1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
